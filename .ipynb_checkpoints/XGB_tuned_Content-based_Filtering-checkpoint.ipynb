{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Gradient Boosting Classifier - Content-based Filtering\n",
    "---\n",
    "\n",
    "- Importing the relevant libraries first..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "import random\n",
    "#import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from os import path   #uncomment these if you have downloaded and installed wordcloud based on the instructions above\n",
    "#from PIL import Image\n",
    "#from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing X_legit and y which contain the shops that userid 2043 rated and ratings respectively\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935, 19498)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_legit = pd.read_csv('yelp_data/xlegit.csv')\n",
    "X_legit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4.0\n",
       "1    4.0\n",
       "2    4.0\n",
       "3    4.0\n",
       "4    4.0\n",
       "Name: user_ratings, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('yelp_data/y.csv', squeeze=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset into train and test sets first\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_legit, y, test_size=0.2, random_state=42, stratify=X_legit['userids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290     488\n",
       "1330    789\n",
       "1567    209\n",
       "Name: userids, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.userids.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36      488\n",
       "38      209\n",
       "245     789\n",
       "273     488\n",
       "290     488\n",
       "       ... \n",
       "2580    488\n",
       "2783    209\n",
       "2839    209\n",
       "2844    488\n",
       "2862    209\n",
       "Name: userids, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_legit[X_legit['userids'].isin([488,789,209])]['userids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    0.506814\n",
       "5.0    0.409284\n",
       "3.0    0.075383\n",
       "2.0    0.006388\n",
       "1.0    0.002129\n",
       "Name: user_ratings, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate scaler since not all of the features are of the same scale, eg. review_count and avg_store_rating\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1=X_train.drop(['userids'],axis=1)\n",
    "X_test_1=X_test.drop(['userids'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userids</th>\n",
       "      <th>shops_the-coconut-club-singapore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      userids  shops_the-coconut-club-singapore\n",
       "1657       75                                 0\n",
       "2575       75                                 0\n",
       "915        75                                 0\n",
       "2549       75                                 0\n",
       "2573       75                                 0\n",
       "2004       75                                 0\n",
       "653        75                                 0\n",
       "2915       75                                 0\n",
       "2393       75                                 0\n",
       "1069       75                                 0\n",
       "1636       75                                 0\n",
       "263        75                                 0\n",
       "258        75                                 0\n",
       "1690       75                                 0\n",
       "953        75                                 0\n",
       "2325       75                                 1\n",
       "2726       75                                 0\n",
       "338        75                                 0\n",
       "1426       75                                 0\n",
       "1825       75                                 0\n",
       "318        75                                 0\n",
       "162        75                                 0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train['userids']==75][['userids','shops_the-coconut-club-singapore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the train and transforming both the train and test sets\n",
    "X_train_sc = ss.fit_transform(X_train_1)\n",
    "X_test_sc = ss.transform(X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2348, 19497)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(587, 19497)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following cells have been commented out due to some mistake saving the wrong xgb_model.sav, but fortunately, the best hyperparameters from the tuned model have been saved in the flask app python script and the Simple Hybrid Recommender trial with extn with XGB's notebook...\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "#xgb_model = XGBClassifier(tree_method='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just in case it takes too long to run this even...\n",
    "#cross_val_score(xgb_model,X_train_sc,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_1.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is for initial decision trees tuned\n",
    "#params = {\n",
    " #   'learning_rate' : [0.1, 0.5, 0.9],\n",
    "  #  'n_estimators' : [100,200,300],\n",
    "   # 'max_depth':[6,9,12],\n",
    "    #'gamma':[0,1,2,3],\n",
    "    #'max_delta_step':[1,2,3],\n",
    "\n",
    "    #'scale_pos_weight':[0.5, 1, 2, 3]\n",
    "  #  } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#took too long to run...to be run as part of future plans for this project\n",
    "#xgb_gridsearch = GridSearchCV(xgb_model, params, cv = 5, verbose = 1, n_jobs = -1)\n",
    "#xgb_gridsearch.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_2.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Gridsearch best score: ', xgb_gridsearch.best_score_)\n",
    "#print('Gridsearch best estimator: ', xgb_gridsearch.best_estimator_)\n",
    "#print('Gridsearch best score on test set: ', xgb_gridsearch.best_estimator_.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_3.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a filename for tuned model\n",
    "#filename = 'xgb_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the tuned model just in case of need to retrieve it in future\n",
    "#joblib.dump(xgb_gridsearch,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to demonstrate loading of saved model just in case...\n",
    "#loaded_model = joblib.load('yelp_data/xgb_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.best_estimator_.score(X_test_sc,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acc on test was 0.97!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check out the tuned params for usage in deployment on Heroku\n",
    "loaded_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating recommendations for userid 2043 based on XGB model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacking X_test as first step in regenerating the shops column for predictions\n",
    "#trial = X_test.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #creating loop to re-generate original X_test order of shops\n",
    "# index_lst = []\n",
    "# outlets_lst = []\n",
    "# for n in range(len(trial.index)):\n",
    "#     if trial.index[n][1].startswith('shops_') and trial[n]!=0:\n",
    "#         index_lst.append(str(trial.index[n][0]))\n",
    "#         outlets_lst.append(trial.index[n][1])\n",
    "# index_lst = [int(x) for x in index_lst]\n",
    "# reconstructed_X_test = pd.DataFrame({'shops':outlets_lst}, index=index_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating column of rating predictions\n",
    "#rating_predictions = loaded_model.best_estimator_.predict(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column of rating predictions into reconstructed df\n",
    "#reconstructed_X_test['predicted_ratings']=rating_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the actual ratings into the reconstructed df for comparison later on...\n",
    "#reconstructed_X_test['actual_ratings']=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_X_test['userids'] = X_test.userids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_X_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing top 5 rows based on content-based filtering (using xgb classifier) predictions to get a sense...\n",
    "#reconstructed_X_test.sort_values('predicted_ratings', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_11.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving this reconstructed_X_test for fusion with collab X_test to evaluate hybrid system later on. \n",
    "#reconstructed_X_test.to_csv('yelp_data/xgb_hundten_cb_pred_actual.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_X_test[(reconstructed_X_test['userids']==75)&(reconstructed_X_test['shops']=='shops_the-coconut-club-singapore')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reconstructed_X_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions for evaluation of model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #defining function for obtaining tn, fp, fn, tp for each rating class for feeding into micro-avg precision and recall functions defined below\n",
    "# def cm_spec(y_true,y_pred,rating,state):\n",
    "#     if state=='tn':\n",
    "#         return multilabel_confusion_matrix(y_true,y_pred)[rating-1][0][0]\n",
    "#     elif state=='fp':\n",
    "#         return multilabel_confusion_matrix(y_true,y_pred)[rating-1][0][1]\n",
    "#     elif state=='fn':\n",
    "#         return multilabel_confusion_matrix(y_true,y_pred)[rating-1][1][0]\n",
    "#     else:\n",
    "#         return multilabel_confusion_matrix(y_true,y_pred)[rating-1][1][1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #defining function for obtaining micro-avg precision\n",
    "# def micro_avg_precision(y_true,y_pred):\n",
    "#     return ((cm_spec(y_true,y_pred,1,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'tp'))/(\n",
    "#                                                 cm_spec(y_true,y_pred,1,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'tp')+\n",
    "#                                                 cm_spec(y_true,y_pred,1,'fp')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'fp')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'fp')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'fp')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'fp')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #defining function for obtaining micro-avg recall\n",
    "# def micro_avg_recall(y_true,y_pred):\n",
    "#     return ((cm_spec(y_true,y_pred,1,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'tp'))/(\n",
    "#                                                 cm_spec(y_true,y_pred,1,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'tp')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'tp')+\n",
    "#                                                 cm_spec(y_true,y_pred,1,'fn')+\n",
    "#                                                  cm_spec(y_true,y_pred,2,'fn')+\n",
    "#                                                  cm_spec(y_true,y_pred,3,'fn')+\n",
    "#                                                  cm_spec(y_true,y_pred,4,'fn')+\n",
    "#                                                  cm_spec(y_true,y_pred,5,'fn')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #defining function for obtaining micro_avg_f1\n",
    "# def micro_avg_f1(y_true,y_pred):\n",
    "#     return 2 * ((micro_avg_precision(y_true,y_pred) * micro_avg_recall(y_true,y_pred))/(micro_avg_precision(y_true,y_pred) + micro_avg_recall(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function to print out confusion matrix breakdown for each rating class\n",
    "# def confusion_breakdown(y_true,y_pred,rating):\n",
    "#     print(\"True negatives for rating {}: {}\".format(\n",
    "#         rating,multilabel_confusion_matrix(y_true,y_pred)[rating-1][0][0]))\n",
    "#     print(\"False positives for rating {}: {}\".format(\n",
    "#         rating,multilabel_confusion_matrix(y_true,y_pred)[rating-1][0][1]))\n",
    "#     print(\"False negatives for rating {}: {}\".format(\n",
    "#         rating,multilabel_confusion_matrix(y_true,y_pred)[rating-1][1][0]))\n",
    "#     print(\"True positives for rating {}: {}\".format(\n",
    "#         rating,multilabel_confusion_matrix(y_true,y_pred)[rating-1][1][1]))\n",
    "#     return \"******************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(confusion_breakdown(y_test,rating_predictions,1))\n",
    "# print(confusion_breakdown(y_test,rating_predictions,2))\n",
    "# print(confusion_breakdown(y_test,rating_predictions,3))\n",
    "# print(confusion_breakdown(y_test,rating_predictions,4))\n",
    "# print(confusion_breakdown(y_test,rating_predictions,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_6.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can tell it is able to predict correctly most of the rating classes!\n",
    "#y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Gridsearched XGB Classifier with balanced class_weight yielded micro_avg_precision of \", micro_avg_precision(y_test,rating_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Gridsearched XGB Classifier with balanced class_weight yielded micro_avg_recall of \", micro_avg_recall(y_test,rating_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Gridsearched XGB Classifier with balanced class_weight yielded micro_avg_f1 of \", micro_avg_f1(y_test,rating_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_10.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision, recall, f1 of all rating classes show good performance!\n",
    "#print(classification_report(y_test,rating_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_7.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating and plotting the multiclass ROC AUC as part of model evaluation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #making a copy of X_legit and y for computation and plotting of ROC AUC for the respective rating classes and micro-average\n",
    "# X_copy = X_legit.copy()\n",
    "\n",
    "# y_copy = y.copy()\n",
    "\n",
    "# # Binarize the output\n",
    "# y_copy = label_binarize(y_copy, classes=[1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "# n_classes = y_copy.shape[1]\n",
    "\n",
    "# # shuffle and split training and test sets\n",
    "# X_copy_train, X_copy_test, y_copy_train, y_copy_test = train_test_split(X_copy, y_copy, test_size=0.2,\n",
    "#                                                     random_state=42, stratify=y_copy)\n",
    "\n",
    "# #instantiate scaler since not all of the features are of the same scale, eg. review_count and avg_store_rating\n",
    "# ss1 = StandardScaler()\n",
    "\n",
    "# #fitting the train and transforming both the train and test sets\n",
    "# X_copy_train_sc = ss1.fit_transform(X_copy_train)\n",
    "# X_copy_test_sc = ss1.transform(X_copy_test)\n",
    "\n",
    "# # Learn to predict each class against the other using the params of tuned model with random_state set to 42 so that the values and curves do not waver\n",
    "# classifier = OneVsRestClassifier(XGBClassifier(learning_rate=0.5, max_depth=9, n_estimators=200, random_state=42))\n",
    "# y_score = classifier.fit(X_copy_train_sc, y_copy_train).predict_proba(X_copy_test_sc)\n",
    "\n",
    "# # Compute ROC curve and ROC area for each class\n",
    "# fpr = dict()\n",
    "# tpr = dict()\n",
    "# roc_auc = dict()\n",
    "# for i in range(n_classes):\n",
    "#     fpr[i], tpr[i], _ = roc_curve(y_copy_test[:, i], y_score[:, i])\n",
    "#     roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# # Compute micro-average ROC curve and ROC area\n",
    "# fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_copy_test.ravel(), y_score.ravel())\n",
    "# roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# # Plot all ROC curves and micro-averaged one\n",
    "# plt.figure(figsize=(12,9))\n",
    "# lw=2\n",
    "# plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "#          label='micro-average ROC curve (area = {0:0.2f})'\n",
    "#                ''.format(roc_auc[\"micro\"]), linestyle=':', linewidth=4)\n",
    "# for i in range(n_classes):\n",
    "#     plt.plot(fpr[i], tpr[i], lw=lw,\n",
    "#              label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "#              ''.format(i+1, roc_auc[i]))\n",
    "\n",
    "# plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('1-Specificity',fontsize=20)\n",
    "# plt.ylabel('Sensitivity',fontsize=20)\n",
    "# plt.title('ROC AUC for XGB w Tfidf',fontsize=20)\n",
    "# plt.legend(loc=\"lower right\",fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculating one-vs-one and one-vs-rest micro-averaged ROC AUC to check if there is a difference between both\n",
    "# y_prob = classifier.predict_proba(X_copy_test_sc)\n",
    "# micro_roc_auc_ovo = roc_auc_score(y_copy_test, y_prob, multi_class=\"ovo\",\n",
    "#                                      average=\"micro\")\n",
    "# micro_roc_auc_ovr = roc_auc_score(y_copy_test, y_prob, multi_class=\"ovr\",\n",
    "#                                      average=\"micro\")\n",
    "# print(\"One-vs-One ROC AUC score:\\n{:.6f} \"\n",
    "#       \"(micro-averaged)\"\n",
    "#       .format(micro_roc_auc_ovo))\n",
    "# print(\"One-vs-Rest ROC AUC score:\\n{:.6f} \"\n",
    "#       \"(micro-averaged)\"\n",
    "#       .format(micro_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_8.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calculating one-vs-one and one-vs-rest ROC AUC weighted by prevalence to check if there is a difference between both\n",
    "# y_prob = classifier.predict_proba(X_copy_test_sc)\n",
    "# weighted_roc_auc_ovo = roc_auc_score(y_copy_test, y_prob, multi_class=\"ovo\",\n",
    "#                                      average=\"weighted\")\n",
    "# weighted_roc_auc_ovr = roc_auc_score(y_copy_test, y_prob, multi_class=\"ovr\",\n",
    "#                                      average=\"weighted\")\n",
    "# print(\"One-vs-One ROC AUC score:\\n{:.6f} \"\n",
    "#       \"(weighted by prevalence)\"\n",
    "#       .format(weighted_roc_auc_ovo))\n",
    "# print(\"One-vs-Rest ROC AUC score:\\n{:.6f} \"\n",
    "#       \"(weighted by prevalence)\"\n",
    "#       .format(weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_data/xgb_9.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
